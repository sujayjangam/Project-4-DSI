{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0669e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import datetime as dt\n",
    "from dateutil.parser import *\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from numpy import argmax\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score,classification_report, roc_auc_score,accuracy_score, \\\n",
    "precision_score, f1_score, recall_score, roc_curve\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import re\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rc('xtick', labelsize=12) \n",
    "plt.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ac99645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression = pd.read_csv('../data/merged_train_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c27b2160",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_regression = pd.read_csv('../data/merged_test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d022cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.948107\n",
       "1    0.051893\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_regression.drop(['wnvpresent'],axis=1)\n",
    "y = df_regression['wnvpresent']\n",
    "\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fd2a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(x,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea4a6f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "x_train, y_train = sm.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "251105ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "x_train_sc = ss.fit_transform(x_train)\n",
    "x_test_sc = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d43ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "models = {'lr': LogisticRegression(max_iter=5_000, random_state=42, solver='saga'),\n",
    "          'rf': RandomForestClassifier(random_state=42),\n",
    "          'gb': GradientBoostingClassifier(random_state=42),\n",
    "          'et': ExtraTreesClassifier(random_state=42),\n",
    "          'ada': AdaBoostClassifier(random_state=42),\n",
    "          'svc': SVC(random_state=42, probability=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ba6eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run model -- input model\n",
    "def get_model_scores(model_name,\n",
    "                     mod, \n",
    "                     mod_params={}, \n",
    "                     grid_search=False):\n",
    "    \n",
    "    \"\"\"Function accepts following inputs:\n",
    "    Name of model (str), model to be used (str), \n",
    "    model params(dict, optional), grid_seach(boolean, optional)\n",
    "    If grid_search is True, then please also input the relevant \n",
    "    params for GridSearching\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty dict for appending results\n",
    "    results = {}\n",
    "    \n",
    "    # instantiate pipe\n",
    "    pipe = Pipeline([\n",
    "            (mod, models[mod])\n",
    "            ])\n",
    "    \n",
    "    # check if GridSearch true or false\n",
    "    if grid_search:\n",
    "        \n",
    "        # combine vectorizer and mod params together\n",
    "        gs_params = {}\n",
    "        gs_params.update(mod_params)\n",
    "        \n",
    "        # instantiate GridSearchCV\n",
    "        gs = GridSearchCV(pipe, \n",
    "                          param_grid=gs_params,\n",
    "                          cv=5, \n",
    "                          verbose=2, \n",
    "                          n_jobs=-1)\n",
    "        \n",
    "        # fit model\n",
    "        gs.fit(x_train_sc, y_train)\n",
    "        pipe = gs\n",
    "        \n",
    "    else:\n",
    "        # else fit model\n",
    "        pipe.fit(x_train_sc, y_train)\n",
    "    \n",
    "    # create predictions and confusion matrix\n",
    "    predictions = pipe.predict(x_test_sc)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    y_test_pred_prob = pipe.predict_proba(x_test_sc)[:,1]\n",
    "    y_train_pred_prob = pipe.predict_proba(x_train_sc)[:,1]\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred_prob)\n",
    "    test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    \n",
    "    # Retrieve metrics and add to results\n",
    "    results['model_name'] = model_name\n",
    "    results['model'] = mod\n",
    "    results['train_score'] = pipe.score(x_train_sc, y_train)\n",
    "    results['test_score'] = pipe.score(x_test_sc, y_test)\n",
    "    \n",
    "    results['recall'] = recall_score(y_test, \n",
    "                                     predictions)\n",
    "    \n",
    "    results['specificity'] = tn/(tn + fp)\n",
    "    \n",
    "    results['precision'] = precision_score(y_test, \n",
    "                                           predictions)\n",
    "    \n",
    "    results['train_auc'] = roc_auc_score(y_train, y_train_pred_prob)\n",
    "    results['test_auc'] = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    \n",
    "    results['is_tuned'] = grid_search\n",
    "    \n",
    "    if grid_search:\n",
    "        print('BEST PARAMS-->')\n",
    "        display(pipe.best_params_)\n",
    "    \n",
    "    # add results to list for model evaluation later\n",
    "    model_eval.append(results)\n",
    "    \n",
    "    print('METRICS-->')\n",
    "    display(results)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    \n",
    "    print(f\"True Negatives: {tn}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"True Positives: {tp}\")\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce484811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to store results\n",
    "model_eval =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e455ed0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'lr_base',\n",
       " 'model': 'lr',\n",
       " 'train_score': 0.9572568940493469,\n",
       " 'test_score': 0.9360561056105611,\n",
       " 'recall': 0.06451612903225806,\n",
       " 'specificity': 0.9830434782608696,\n",
       " 'precision': 0.1702127659574468,\n",
       " 'train_auc': 0.9881001472443814,\n",
       " 'test_auc': 0.7398650070126227,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2261\n",
      "False Positives: 39\n",
      "False Negatives: 116\n",
      "True Positives: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('lr',\n",
       "                 LogisticRegression(max_iter=5000, random_state=42,\n",
       "                                    solver='saga'))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_base = get_model_scores('lr_base', 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b03a44a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9569264955894103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9585867361714451"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9306930693069307"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr_scores = cross_val_score(lr, x_train_sc , y_train, cv=5)\n",
    "\n",
    "lr.fit(x_train_sc,y_train)\n",
    "\n",
    "display(np.mean(lr_scores))\n",
    "\n",
    "display(lr.score(x_train_sc,y_train))\n",
    "\n",
    "display(lr.score(x_test_sc,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "516b7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(x_test_sc)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "y_test_pred_prob = lr.predict_proba(x_test_sc)[:,1]\n",
    "y_train_pred_prob = lr.predict_proba(x_train_sc)[:,1]\n",
    "\n",
    "train_auc = roc_auc_score(y_train, y_train_pred_prob)\n",
    "test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "\n",
    "display(train_auc)\n",
    "display(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9606e335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9556238522757143"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9614827686070084"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9352310231023102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm = SVC(probability=True)\n",
    "\n",
    "svm_scores = cross_val_score(svm, x_train_sc , y_train, cv=5)\n",
    "\n",
    "svm.fit(x_train_sc,y_train)\n",
    "\n",
    "display(np.mean(svm_scores))\n",
    "\n",
    "display(svm.score(x_train_sc,y_train))\n",
    "\n",
    "display(svm.score(x_test_sc,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58773052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9937922123146546"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7117353640230173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = svm.predict(x_test_sc)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "y_test_pred_prob = svm.predict_proba(x_test_sc)[:,1]\n",
    "y_train_pred_prob = svm.predict_proba(x_train_sc)[:,1]\n",
    "\n",
    "train_auc = roc_auc_score(y_train, y_train_pred_prob)\n",
    "test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "\n",
    "display(train_auc)\n",
    "display(test_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
