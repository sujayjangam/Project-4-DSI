{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e1bb731",
   "metadata": {},
   "source": [
    "## All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0669e1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import datetime as dt\n",
    "from dateutil.parser import *\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from numpy import argmax\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report, accuracy_score, \\\n",
    "precision_score, f1_score, recall_score, roc_curve, auc, RocCurveDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import re\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rc('xtick', labelsize=12) \n",
    "plt.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dbfd03",
   "metadata": {},
   "source": [
    "### Reading in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ac99645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression = pd.read_csv('../data/merged_train_final.csv')\n",
    "df_multi = pd.read_csv('../data/merged_train_multi.csv')\n",
    "\n",
    "test_df_regression = pd.read_csv('../data/merged_test_final.csv')\n",
    "test_df_multi = pd.read_csv('../data/merged_test_multi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d022cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.948107\n",
       "1    0.051893\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining x and y for our dataset with multi-collinearity\n",
    "x = df_multi.drop(['wnvpresent'],axis=1)\n",
    "y = df_multi['wnvpresent']\n",
    "\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ccfffb",
   "metadata": {},
   "source": [
    "As we can see from the above output, our target `y` is very imbalanced. It is not advisable to conduct modeling on such a dataset, as such we will be using a technique known as **Synthetic Minority Oversampling Technique** (SMOTE for short) to help us rebalance the two classes before we do any modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fd2a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split on our previously defined x and y\n",
    "x_train, x_test, y_train, y_test= train_test_split(x,y,random_state=42)\n",
    "\n",
    "# scaling our features before using SMOTE\n",
    "ss = StandardScaler()\n",
    "x_train_sc = ss.fit_transform(x_train)\n",
    "x_test_sc = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "697f1a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "# resample on our train data\n",
    "x_train_sc, y_train = sm.fit_resample(x_train_sc,y_train)\n",
    "\n",
    "# sanity check to ensure our classes are balanced now\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d43ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "models = {'lr': LogisticRegression(max_iter=5_000, random_state=42, solver='saga'),\n",
    "          'rf': RandomForestClassifier(random_state=42),\n",
    "          'gb': GradientBoostingClassifier(random_state=42),\n",
    "          'et': ExtraTreesClassifier(random_state=42),\n",
    "          'ada': AdaBoostClassifier(random_state=42),\n",
    "          'svm': SVC(random_state=42, probability=True),\n",
    "          'xgb': XGBClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ba6eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run model -- input model\n",
    "def get_model_scores(model_name,\n",
    "                     mod, \n",
    "                     mod_params={}, \n",
    "                     grid_search=False):\n",
    "    \n",
    "    \"\"\"Function accepts following inputs:\n",
    "    Name of model (str), model to be used (str), \n",
    "    model params(dict, optional), grid_seach(boolean, optional)\n",
    "    If grid_search is True, then please also input the relevant \n",
    "    params for GridSearching\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty dict for appending results\n",
    "    results = {}\n",
    "    \n",
    "    # instantiate pipe\n",
    "    pipe = Pipeline([\n",
    "            (mod, models[mod])\n",
    "            ])\n",
    "    \n",
    "    # check if GridSearch true or false\n",
    "    if grid_search:\n",
    "        \n",
    "        # combine vectorizer and mod params together\n",
    "        gs_params = {}\n",
    "        gs_params.update(mod_params)\n",
    "        \n",
    "        # instantiate GridSearchCV\n",
    "        gs = GridSearchCV(pipe, \n",
    "                          param_grid=gs_params,\n",
    "                          cv=5, \n",
    "                          verbose=2, \n",
    "                          n_jobs=-1)\n",
    "        \n",
    "        # fit model\n",
    "        gs.fit(x_train_sc, y_train)\n",
    "        pipe = gs\n",
    "        \n",
    "    else:\n",
    "        # else fit model\n",
    "        pipe.fit(x_train_sc, y_train)\n",
    "    \n",
    "    # create predictions and confusion matrix\n",
    "    predictions = pipe.predict(x_test_sc)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    y_test_pred_prob = pipe.predict_proba(x_test_sc)[:,1]\n",
    "    y_train_pred_prob = pipe.predict_proba(x_train_sc)[:,1]\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred_prob)\n",
    "    test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    \n",
    "    # Retrieve metrics and add to results\n",
    "    results['model_name'] = model_name\n",
    "    results['model'] = mod\n",
    "    results['train_score'] = pipe.score(x_train_sc, y_train)\n",
    "    results['test_score'] = pipe.score(x_test_sc, y_test)\n",
    "    \n",
    "    results['recall'] = recall_score(y_test, \n",
    "                                     predictions)\n",
    "    \n",
    "    results['specificity'] = tn/(tn + fp)\n",
    "    \n",
    "    results['precision'] = precision_score(y_test, \n",
    "                                           predictions)\n",
    "    \n",
    "    results['train_auc'] = roc_auc_score(y_train, y_train_pred_prob)\n",
    "    results['test_auc'] = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    \n",
    "    results['is_tuned'] = grid_search\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, lr_base_multi.predict(x_test_sc))\n",
    "    results['fpr'] = fpr\n",
    "    results['tpr'] = tpr\n",
    "    \n",
    "    if grid_search:\n",
    "        print('BEST PARAMS-->')\n",
    "        display(pipe.best_params_)\n",
    "    \n",
    "    # add results to list for model evaluation later\n",
    "    model_eval.append(results)\n",
    "    \n",
    "    print('METRICS-->')\n",
    "    display(results)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    \n",
    "    print(f\"True Negatives: {tn}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"True Positives: {tp}\")\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce484811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to store results\n",
    "model_eval =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598c8a32",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba10b8",
   "metadata": {},
   "source": [
    "For this section, we will not be adding any parameters to our models in order to have a baseline for each model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f07df21",
   "metadata": {},
   "source": [
    "### Dataset with Features with multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "75433c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_base_multi.steps[0][1].n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9468937c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'lr_base_multi',\n",
       " 'model': 'lr',\n",
       " 'train_score': 0.8259796806966618,\n",
       " 'test_score': 0.775990099009901,\n",
       " 'recall': 0.6048387096774194,\n",
       " 'specificity': 0.7852173913043479,\n",
       " 'precision': 0.13181019332161686,\n",
       " 'train_auc': 0.8874044228083443,\n",
       " 'test_auc': 0.7729926367461429,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1806\n",
      "False Positives: 494\n",
      "False Negatives: 49\n",
      "True Positives: 75\n"
     ]
    }
   ],
   "source": [
    "lr_base_multi = get_model_scores('lr_base_multi', 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a498db30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'svm_base_multi',\n",
       " 'model': 'svm',\n",
       " 'train_score': 0.9298984034833091,\n",
       " 'test_score': 0.8535478547854786,\n",
       " 'recall': 0.45161290322580644,\n",
       " 'specificity': 0.8752173913043478,\n",
       " 'precision': 0.16326530612244897,\n",
       " 'train_auc': 0.9783968162352202,\n",
       " 'test_auc': 0.777312412342216,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2013\n",
      "False Positives: 287\n",
      "False Negatives: 68\n",
      "True Positives: 56\n"
     ]
    }
   ],
   "source": [
    "svm_base_multi = get_model_scores('svm_base_multi', 'svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2270f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:48:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'xg_base_multi',\n",
       " 'model': 'xgb',\n",
       " 'train_score': 0.978011611030479,\n",
       " 'test_score': 0.9422442244224423,\n",
       " 'recall': 0.0967741935483871,\n",
       " 'specificity': 0.9878260869565217,\n",
       " 'precision': 0.3,\n",
       " 'train_auc': 0.9974362836276467,\n",
       " 'test_auc': 0.8528962131837308,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2272\n",
      "False Positives: 28\n",
      "False Negatives: 112\n",
      "True Positives: 12\n"
     ]
    }
   ],
   "source": [
    "xg_base_multi = get_model_scores('xg_base_multi', 'xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e455ed0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'rf_base_multi',\n",
       " 'model': 'rf',\n",
       " 'train_score': 0.9918722786647315,\n",
       " 'test_score': 0.9434818481848185,\n",
       " 'recall': 0.07258064516129033,\n",
       " 'specificity': 0.9904347826086957,\n",
       " 'precision': 0.2903225806451613,\n",
       " 'train_auc': 0.9997484522487946,\n",
       " 'test_auc': 0.7970950210378681,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2278\n",
      "False Positives: 22\n",
      "False Negatives: 115\n",
      "True Positives: 9\n"
     ]
    }
   ],
   "source": [
    "rf_base_multi = get_model_scores('rf_base_multi', 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e306a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'et_base_multi',\n",
       " 'model': 'et',\n",
       " 'train_score': 0.9918722786647315,\n",
       " 'test_score': 0.9426567656765676,\n",
       " 'recall': 0.06451612903225806,\n",
       " 'specificity': 0.99,\n",
       " 'precision': 0.25806451612903225,\n",
       " 'train_auc': 0.9998393056131918,\n",
       " 'test_auc': 0.70117110799439,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2277\n",
      "False Positives: 23\n",
      "False Negatives: 116\n",
      "True Positives: 8\n"
     ]
    }
   ],
   "source": [
    "et_base_multi = get_model_scores('et_base_multi', 'et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "46b32cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'gb_base_multi',\n",
       " 'model': 'gb',\n",
       " 'train_score': 0.9555152394775036,\n",
       " 'test_score': 0.9377062706270627,\n",
       " 'recall': 0.20161290322580644,\n",
       " 'specificity': 0.9773913043478261,\n",
       " 'precision': 0.3246753246753247,\n",
       " 'train_auc': 0.9905579909041311,\n",
       " 'test_auc': 0.8335729312762974,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2248\n",
      "False Positives: 52\n",
      "False Negatives: 99\n",
      "True Positives: 25\n"
     ]
    }
   ],
   "source": [
    "gb_base_multi = get_model_scores('gb_base_multi', 'gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c82206e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'ada_base_multi',\n",
       " 'model': 'ada',\n",
       " 'train_score': 0.9322931785195936,\n",
       " 'test_score': 0.9129537953795379,\n",
       " 'recall': 0.3870967741935484,\n",
       " 'specificity': 0.941304347826087,\n",
       " 'precision': 0.26229508196721313,\n",
       " 'train_auc': 0.9820600415823189,\n",
       " 'test_auc': 0.8415410238429173,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2165\n",
      "False Positives: 135\n",
      "False Negatives: 76\n",
      "True Positives: 48\n"
     ]
    }
   ],
   "source": [
    "ada_base_multi = get_model_scores('ada_base_multi', 'ada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b514439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2ba262c",
   "metadata": {},
   "source": [
    "### Dataset with Features with minimal multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f6d6a3",
   "metadata": {},
   "source": [
    "First we will have to reset our `x` and `y` for the new dataset to feed into our modeling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8ae06a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.948107\n",
       "1    0.051893\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redefining our x, y for the new dataset\n",
    "x = df_regression.drop(['wnvpresent'],axis=1)\n",
    "y = df_regression['wnvpresent']\n",
    "\n",
    "# check for imbalance, \n",
    "# expected to be same as previously seen\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0ae620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split on our previously defined x and y\n",
    "x_train, x_test, y_train, y_test= train_test_split(x,y,random_state=42)\n",
    "\n",
    "# scaling our features before using SMOTE\n",
    "ss = StandardScaler()\n",
    "x_train_sc = ss.fit_transform(x_train)\n",
    "x_test_sc = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e06f1203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "# resample on our train data\n",
    "x_train_sc, y_train = sm.fit_resample(x_train_sc,y_train)\n",
    "\n",
    "# sanity check to ensure our classes are balanced now\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104cbedb",
   "metadata": {},
   "source": [
    "Now we are ready to begin modeling for the dataset with minimal multi-collinearity. For simplicity's sake, we will refer to these models with the suffix `_reg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "858b781a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'lr_base_reg',\n",
       " 'model': 'lr',\n",
       " 'train_score': 0.8057329462989841,\n",
       " 'test_score': 0.7541254125412541,\n",
       " 'recall': 0.5887096774193549,\n",
       " 'specificity': 0.7630434782608696,\n",
       " 'precision': 0.11812297734627832,\n",
       " 'train_auc': 0.8751527212826059,\n",
       " 'test_auc': 0.7461448106591865,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1755\n",
      "False Positives: 545\n",
      "False Negatives: 51\n",
      "True Positives: 73\n"
     ]
    }
   ],
   "source": [
    "lr_base_reg = get_model_scores('lr_base_reg', 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2063e490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'svm_base_reg',\n",
       " 'model': 'svm',\n",
       " 'train_score': 0.9130624092888244,\n",
       " 'test_score': 0.8407590759075908,\n",
       " 'recall': 0.4274193548387097,\n",
       " 'specificity': 0.8630434782608696,\n",
       " 'precision': 0.14402173913043478,\n",
       " 'train_auc': 0.9712810577160058,\n",
       " 'test_auc': 0.7514708976157083,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1985\n",
      "False Positives: 315\n",
      "False Negatives: 71\n",
      "True Positives: 53\n"
     ]
    }
   ],
   "source": [
    "svm_base_reg = get_model_scores('svm_base_reg', 'svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "113b60eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:51:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'xg_base_reg',\n",
       " 'model': 'xgb',\n",
       " 'train_score': 0.9776487663280116,\n",
       " 'test_score': 0.9426567656765676,\n",
       " 'recall': 0.08064516129032258,\n",
       " 'specificity': 0.9891304347826086,\n",
       " 'precision': 0.2857142857142857,\n",
       " 'train_auc': 0.9971802490304831,\n",
       " 'test_auc': 0.8572072230014025,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2275\n",
      "False Positives: 25\n",
      "False Negatives: 114\n",
      "True Positives: 10\n"
     ]
    }
   ],
   "source": [
    "xg_base_reg = get_model_scores('xg_base_reg', 'xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "673015ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'rf_base_reg',\n",
       " 'model': 'rf',\n",
       " 'train_score': 0.9918722786647315,\n",
       " 'test_score': 0.9418316831683168,\n",
       " 'recall': 0.06451612903225806,\n",
       " 'specificity': 0.9891304347826086,\n",
       " 'precision': 0.24242424242424243,\n",
       " 'train_auc': 0.9997510643093522,\n",
       " 'test_auc': 0.7902559607293127,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2275\n",
      "False Positives: 25\n",
      "False Negatives: 116\n",
      "True Positives: 8\n"
     ]
    }
   ],
   "source": [
    "rf_base_reg = get_model_scores('rf_base_reg', 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8c0b0992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'et_base_reg',\n",
       " 'model': 'et',\n",
       " 'train_score': 0.9918722786647315,\n",
       " 'test_score': 0.941006600660066,\n",
       " 'recall': 0.07258064516129033,\n",
       " 'specificity': 0.9878260869565217,\n",
       " 'precision': 0.24324324324324326,\n",
       " 'train_auc': 0.9998393056131918,\n",
       " 'test_auc': 0.6866374474053296,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2272\n",
      "False Positives: 28\n",
      "False Negatives: 115\n",
      "True Positives: 9\n"
     ]
    }
   ],
   "source": [
    "et_base_reg = get_model_scores('et_base_reg', 'et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1f2d3b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'gb_base_reg',\n",
       " 'model': 'gb',\n",
       " 'train_score': 0.9613207547169811,\n",
       " 'test_score': 0.9389438943894389,\n",
       " 'recall': 0.12903225806451613,\n",
       " 'specificity': 0.9826086956521739,\n",
       " 'precision': 0.2857142857142857,\n",
       " 'train_auc': 0.9908925453055584,\n",
       " 'test_auc': 0.8262903225806452,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2260\n",
      "False Positives: 40\n",
      "False Negatives: 108\n",
      "True Positives: 16\n"
     ]
    }
   ],
   "source": [
    "gb_base_reg = get_model_scores('gb_base_reg', 'gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "62a72dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'ada_base_reg',\n",
       " 'model': 'ada',\n",
       " 'train_score': 0.9402757619738752,\n",
       " 'test_score': 0.9261551155115512,\n",
       " 'recall': 0.18548387096774194,\n",
       " 'specificity': 0.9660869565217391,\n",
       " 'precision': 0.22772277227722773,\n",
       " 'train_auc': 0.9831208330787979,\n",
       " 'test_auc': 0.8237394810659187,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2222\n",
      "False Positives: 78\n",
      "False Negatives: 101\n",
      "True Positives: 23\n"
     ]
    }
   ],
   "source": [
    "ada_base_reg = get_model_scores('ada_base_reg', 'ada')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3fa598",
   "metadata": {},
   "source": [
    "Now let's evaluate all our models and see which model, and which dataset has performed the best. Based on this, we will decide which models to further tune.<br>\n",
    "The main metrics we are looking for are `recall` and `test_auc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6ce0a04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>recall</th>\n",
       "      <th>test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_base_multi</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.604839</td>\n",
       "      <td>0.772993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lr_base_reg</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.588710</td>\n",
       "      <td>0.746145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm_base_multi</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.777312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm_base_reg</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.427419</td>\n",
       "      <td>0.751471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ada_base_multi</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.841541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gb_base_multi</td>\n",
       "      <td>gb</td>\n",
       "      <td>0.201613</td>\n",
       "      <td>0.833573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ada_base_reg</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.185484</td>\n",
       "      <td>0.823739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gb_base_reg</td>\n",
       "      <td>gb</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.826290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xg_base_multi</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.852896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xg_base_reg</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.857207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf_base_multi</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.797095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>et_base_reg</td>\n",
       "      <td>et</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.686637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rf_base_reg</td>\n",
       "      <td>rf</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.790256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>et_base_multi</td>\n",
       "      <td>et</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.701171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model_name model    recall  test_auc\n",
       "0    lr_base_multi    lr  0.604839  0.772993\n",
       "7      lr_base_reg    lr  0.588710  0.746145\n",
       "1   svm_base_multi   svm  0.451613  0.777312\n",
       "8     svm_base_reg   svm  0.427419  0.751471\n",
       "6   ada_base_multi   ada  0.387097  0.841541\n",
       "5    gb_base_multi    gb  0.201613  0.833573\n",
       "13    ada_base_reg   ada  0.185484  0.823739\n",
       "12     gb_base_reg    gb  0.129032  0.826290\n",
       "2    xg_base_multi   xgb  0.096774  0.852896\n",
       "9      xg_base_reg   xgb  0.080645  0.857207\n",
       "3    rf_base_multi    rf  0.072581  0.797095\n",
       "11     et_base_reg    et  0.072581  0.686637\n",
       "10     rf_base_reg    rf  0.064516  0.790256\n",
       "4    et_base_multi    et  0.064516  0.701171"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_scores = pd.DataFrame(model_eval)\n",
    "\n",
    "base_model_scores.sort_values(by=['recall', \n",
    "                                  'test_auc'], \n",
    "                              ascending=False)[['model_name', \n",
    "                                                'model','recall', \n",
    "                                                'test_auc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8f57a0",
   "metadata": {},
   "source": [
    "Since our scores are better using the dataset with features having multi-collinearity, we will continue using that dataset moving foward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "02be4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving our base_model_scores to csv in order to refer to them again if required.\n",
    "base_model_scores.to_csv('../data/base_model_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8308784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to plot ROC curve\n",
    "def roc_curve_plotter(model_dict, plot_top=False):\n",
    "    \"\"\"Doc String\"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12,10))\n",
    "    axes = {}\n",
    "    auc_scores = []\n",
    "    for i, m in enumerate(model_dict.keys()):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, m.predict(x_test_sc))\n",
    "        auc_scores[i] = auc(fpr, tpr)\n",
    "        axes[f'ax{i}'] = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc_scores[i], name=model_dict[m])\n",
    "    if plot_top:\n",
    "        max_index = auc_scores.index(max(auc_scores))\n",
    "        for i, a in enumerate(axes):\n",
    "            if i != max_index:\n",
    "                axes[a].line_.set_color('lightgrey')\n",
    "    plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--', label='Random Guess')\n",
    "    plt.title('ROC-AUC Curve Comparison', fontsize=22)\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ce41d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary for ROC curve plotter\n",
    "base_model_dict= {\n",
    "    lr_base_multi: 'LogReg_MC',\n",
    "    svm_base_multi: 'SVM_MC',\n",
    "    xg_base_multi: 'XGBoost_MC',\n",
    "    rf_base_multi: 'RandForest_MC',\n",
    "    et_base_multi: 'ExtraTrees_MC',\n",
    "    gb_base_multi: 'GradBoost_MC', \n",
    "    ada_base_multi: 'AdaBoost_MC',\n",
    "    lr_base_reg: 'LogReg_reg',\n",
    "    svm_base_reg: 'SVM_reg',\n",
    "    xg_base_reg: 'XGBoost_reg', \n",
    "    rf_base_reg: 'RandForest_reg', \n",
    "    et_base_reg: 'ExtraTrees_reg',\n",
    "    gb_base_reg: 'GradBoost_reg', \n",
    "    ada_base_reg: 'AdaBoost_reg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7176dd69",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 168 features, but LogisticRegression is expecting 157 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JAYYJA~1\\AppData\\Local\\Temp/ipykernel_7256/1850491938.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mroc_curve_plotter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_model_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\JAYYJA~1\\AppData\\Local\\Temp/ipykernel_7256/842417916.py\u001b[0m in \u001b[0;36mroc_curve_plotter\u001b[1;34m(model_dict, plot_top)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mauc_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_sc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mauc_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'ax{i}'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRocCurveDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauc_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    468\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mavailable_if\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_final_estimator_has\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fit_predict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \"\"\"\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    401\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 168 features, but LogisticRegression is expecting 157 features as input."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 581,
       "width": 719
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_curve_plotter(base_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f203147",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve_plotter(base_model_dict, plot_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb8f3c7",
   "metadata": {},
   "source": [
    "## Tuning our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf9428",
   "metadata": {},
   "source": [
    "Considering that we want to optimize our models for *recall* and *AUC_ROC* scores, we will tune our models for each of these scores, and check their effectiveness against our test data (from `train_test_split`) to see which gives us the best result. <br>\n",
    "As mentioned before, we will only be using the dataset with multi-collinearity as that performed better previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32f9d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefining our model training function with scoring argument\n",
    "\n",
    "# Function to run model -- input model\n",
    "# the 'cs' in the function name stands for 'custom scoring'\n",
    "def get_model_scores_cs(model_name,\n",
    "                     mod, \n",
    "                     mod_params={}, \n",
    "                     grid_search=False, \n",
    "                     scoring=None):\n",
    "    \n",
    "    \"\"\"Function accepts following inputs:\n",
    "    Name of model (str), model to be used (str), \n",
    "    model params(dict, optional), grid_seach(boolean, optional)\n",
    "    If grid_search is True, then please also input the relevant \n",
    "    params for GridSearching\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty dict for appending results\n",
    "    results = {}\n",
    "    \n",
    "    # instantiate pipe\n",
    "    pipe = Pipeline([\n",
    "            (mod, models[mod])\n",
    "            ])\n",
    "    \n",
    "    # check if GridSearch true or false\n",
    "    if grid_search:\n",
    "        \n",
    "        # combine vectorizer and mod params together\n",
    "        gs_params = {}\n",
    "        gs_params.update(mod_params)\n",
    "        \n",
    "        # instantiate GridSearchCV\n",
    "        gs = GridSearchCV(pipe, \n",
    "                          param_grid=gs_params,\n",
    "                          cv=5,\n",
    "                          scoring=scoring,\n",
    "                          verbose=2, \n",
    "                          n_jobs=-1)\n",
    "        \n",
    "        # fit model\n",
    "        gs.fit(x_train_sc, y_train)\n",
    "        pipe = gs\n",
    "        \n",
    "    else:\n",
    "        # else fit model\n",
    "        pipe.fit(x_train_sc, y_train)\n",
    "    \n",
    "    # create predictions and confusion matrix\n",
    "    predictions = pipe.predict(x_test_sc)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    y_test_pred_prob = pipe.predict_proba(x_test_sc)[:,1]\n",
    "    y_train_pred_prob = pipe.predict_proba(x_train_sc)[:,1]\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred_prob)\n",
    "    test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    \n",
    "    # Retrieve metrics and add to results\n",
    "    results['model_name'] = model_name\n",
    "    results['model'] = mod\n",
    "    results['train_score'] = pipe.score(x_train_sc, y_train)\n",
    "    results['test_score'] = pipe.score(x_test_sc, y_test)\n",
    "    \n",
    "    results['recall'] = recall_score(y_test, \n",
    "                                     predictions)\n",
    "    \n",
    "    results['specificity'] = tn/(tn + fp)\n",
    "    \n",
    "    results['precision'] = precision_score(y_test, \n",
    "                                           predictions)\n",
    "    \n",
    "    results['train_auc'] = roc_auc_score(y_train, y_train_pred_prob)\n",
    "    results['test_auc'] = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    \n",
    "    results['is_tuned'] = grid_search\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
    "    results['fpr'] = fpr\n",
    "    results['tpr'] = tpr\n",
    "    \n",
    "    if grid_search:\n",
    "        print('BEST PARAMS-->')\n",
    "        display(pipe.best_params_)\n",
    "    \n",
    "    # add results to list for model evaluation later\n",
    "    model_eval.append(results)\n",
    "    \n",
    "    print('METRICS-->')\n",
    "    display(results)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    \n",
    "    print(f\"True Negatives: {tn}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"True Positives: {tp}\")\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96c4681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to store results\n",
    "model_eval =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42a90e3",
   "metadata": {},
   "source": [
    "### re-splitting train_test_split for dataset with features having multi-collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c5d0392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.948107\n",
       "1    0.051893\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_multi.drop(['wnvpresent'],axis=1)\n",
    "y = df_multi['wnvpresent']\n",
    "\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc40617",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(x,y,random_state=42)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train_sc = ss.fit_transform(x_train)\n",
    "x_test_sc = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ea887d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "x_train_sc, y_train = sm.fit_resample(x_train_sc,y_train)\n",
    "\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76f70463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining each model's tuning parameters\n",
    "\n",
    "ada_params = {'ada__n_estimators': [500, 1000, 1500],\n",
    "              'ada__learning_rate': [0.9, 0.95, 1.0]\n",
    "             }\n",
    "\n",
    "gb_params = {'gb__n_estimators': [500, 1000, 1500],\n",
    "             'gb__learning_rate': [0.2, 0.3, 0.4, 0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "286cac15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gb__learning_rate': 0.4, 'gb__n_estimators': 1000}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'gb_tuned_recall',\n",
       " 'model': 'gb',\n",
       " 'train_score': 0.9824383164005805,\n",
       " 'test_score': 0.20161290322580644,\n",
       " 'recall': 0.20161290322580644,\n",
       " 'specificity': 0.9739130434782609,\n",
       " 'precision': 0.29411764705882354,\n",
       " 'train_auc': 0.9987059030462103,\n",
       " 'test_auc': 0.844773842917251,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2240\n",
      "False Positives: 60\n",
      "False Negatives: 99\n",
      "True Positives: 25\n"
     ]
    }
   ],
   "source": [
    "gb_tuned_recall = get_model_scores_cs('gb_tuned_recall', 'gb', mod_params=gb_params, grid_search=True, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "231d8cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gb__learning_rate': 0.2, 'gb__n_estimators': 1000}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'gb_tuned_roc_auc',\n",
       " 'model': 'gb',\n",
       " 'train_score': 0.9995808801380179,\n",
       " 'test_score': 0.8463025946704067,\n",
       " 'recall': 0.1774193548387097,\n",
       " 'specificity': 0.9782608695652174,\n",
       " 'precision': 0.3055555555555556,\n",
       " 'train_auc': 0.9995808801380179,\n",
       " 'test_auc': 0.8463025946704067,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2250\n",
      "False Positives: 50\n",
      "False Negatives: 102\n",
      "True Positives: 22\n"
     ]
    }
   ],
   "source": [
    "gb_tuned_roc_auc = get_model_scores_cs('gb_tuned_roc_auc', 'gb', mod_params=gb_params, grid_search=True, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3efc2ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ada__learning_rate': 0.9, 'ada__n_estimators': 1500}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'ada_tuned_recall',\n",
       " 'model': 'ada',\n",
       " 'train_score': 0.9512336719883889,\n",
       " 'test_score': 0.1532258064516129,\n",
       " 'recall': 0.1532258064516129,\n",
       " 'specificity': 0.9860869565217392,\n",
       " 'precision': 0.37254901960784315,\n",
       " 'train_auc': 0.9941316373196045,\n",
       " 'test_auc': 0.8490164796633941,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2268\n",
      "False Positives: 32\n",
      "False Negatives: 105\n",
      "True Positives: 19\n"
     ]
    }
   ],
   "source": [
    "ada_tuned_recall = get_model_scores_cs('ada_tuned_recall', 'ada', mod_params=ada_params, grid_search=True, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1afe97fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ada__learning_rate': 1.0, 'ada__n_estimators': 1500}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'ada_tuned_roc_auc',\n",
       " 'model': 'ada',\n",
       " 'train_score': 0.9941689434425695,\n",
       " 'test_score': 0.848883239831697,\n",
       " 'recall': 0.14516129032258066,\n",
       " 'specificity': 0.9847826086956522,\n",
       " 'precision': 0.33962264150943394,\n",
       " 'train_auc': 0.9941689434425695,\n",
       " 'test_auc': 0.848883239831697,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2265\n",
      "False Positives: 35\n",
      "False Negatives: 106\n",
      "True Positives: 18\n"
     ]
    }
   ],
   "source": [
    "ada_tuned_roc_auc = get_model_scores_cs('ada_tuned_roc_auc', 'ada', mod_params=ada_params, grid_search=True, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d09240d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_2 = pd.DataFrame(model_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ae0ec31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>is_tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gb_tuned_recall</td>\n",
       "      <td>gb</td>\n",
       "      <td>0.982438</td>\n",
       "      <td>0.201613</td>\n",
       "      <td>0.201613</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.844774</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gb_tuned_roc_auc</td>\n",
       "      <td>gb</td>\n",
       "      <td>0.999581</td>\n",
       "      <td>0.846303</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.999581</td>\n",
       "      <td>0.846303</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ada_tuned_recall</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.951234</td>\n",
       "      <td>0.153226</td>\n",
       "      <td>0.153226</td>\n",
       "      <td>0.986087</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.994132</td>\n",
       "      <td>0.849016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ada_tuned_roc_auc</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.994169</td>\n",
       "      <td>0.848883</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.984783</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.994169</td>\n",
       "      <td>0.848883</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_name model  train_score  test_score    recall  specificity  \\\n",
       "0    gb_tuned_recall    gb     0.982438    0.201613  0.201613     0.973913   \n",
       "1   gb_tuned_roc_auc    gb     0.999581    0.846303  0.177419     0.978261   \n",
       "2   ada_tuned_recall   ada     0.951234    0.153226  0.153226     0.986087   \n",
       "3  ada_tuned_roc_auc   ada     0.994169    0.848883  0.145161     0.984783   \n",
       "\n",
       "   precision  train_auc  test_auc  is_tuned  \n",
       "0   0.294118   0.998706  0.844774      True  \n",
       "1   0.305556   0.999581  0.846303      True  \n",
       "2   0.372549   0.994132  0.849016      True  \n",
       "3   0.339623   0.994169  0.848883      True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores_2.sort_values('recall', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0613c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_2.to_csv('../data/tuned_models_jay.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd6152b",
   "metadata": {},
   "source": [
    "### Further tuning our best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d422d4",
   "metadata": {},
   "source": [
    "From this table, we can see that although the `test_auc` score is lower for our best logistic regressor, the logisitic regressor peforms best on the recall score. <br>\n",
    "\n",
    "After looking through our features and our model performance, we have decided to test a few other features in hopes of improving our models. The steps we will take are outlined below:\n",
    "\n",
    "1. Initially during feature engineering, we had identified `nummosquitos` as having the highest correlation with our target, `wnvpresent`. To improve our logistic regression model, we will try to use linear regression to first predict the `nummosquitos`, and then passing the predicted value into our model.\n",
    "    * To predict `nummosquitos` we will also pass in the dummified `month` column into our dataset.\n",
    "3. Lastly we will also drop the `species` of mosquitos that did not have any west nile virus detected from our dummified `species` columns.\n",
    "\n",
    "***In the interest of time, we will only use a basic `LinearRegression` model, with all features that have absolute correlation of 10% or more to predict the feature `nummosquitos`.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d081b8",
   "metadata": {},
   "source": [
    "For this process, we will be using the `df_regression` dataset to predict the `nummosquitos`. We will repeat this process on the `test` dataset for later submission on kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "051096d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-reading in our original merged dataset to add the month column to our dataset\n",
    "df_merged = pd.read_csv('../data/weather_train_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f08db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1460e41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi = pd.concat([df_multi, df_merged[['month', 'nummosquitos']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bbd1b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummifying the month column in our regression\n",
    "df_multi = pd.get_dummies(\n",
    "    df_multi,\n",
    "    columns=['month'],\n",
    "    drop_first=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e523fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi['nummosquitos*week'] = df_multi['nummosquitos']*df_multi['week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f53c1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi.to_csv('../data/final_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026f09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11ccd915",
   "metadata": {},
   "source": [
    "Considering that we are going to use the the model to predict the entire dataset of values for nummosquitos, we will be using the entire dataset to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea27b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we will use the suffix 'nm' to indicate that this is for the model to predict 'nummosquitos'\n",
    "# X_nm = df_regression.drop(columns=['wnvpresent', 'nummosquitos'])\n",
    "# y_nm = df_regression['nummosquitos']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918dcd82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83b7c3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.948107\n",
       "1    0.051893\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_multi.drop(['wnvpresent'],axis=1)\n",
    "y = df_multi['wnvpresent']\n",
    "\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4731f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(x,y,random_state=42)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train_sc = ss.fit_transform(x_train)\n",
    "x_test_sc = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a32ba47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "x_train_sc, y_train = sm.fit_resample(x_train_sc,y_train)\n",
    "\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0289f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating params based on previously found best params\n",
    "lr_params_V2 = {\n",
    "    # Trying different types of regularization\n",
    "    'lr__penalty':['l2','l1'],\n",
    "\n",
    "    'lr__C':[20],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18d3b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 20, 'lr__penalty': 'l2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'lr_tuned_lin',\n",
       " 'model': 'lr',\n",
       " 'train_score': 0.9007256894049347,\n",
       " 'test_score': 0.6612903225806451,\n",
       " 'recall': 0.6612903225806451,\n",
       " 'specificity': 0.841304347826087,\n",
       " 'precision': 0.18344519015659955,\n",
       " 'train_auc': 0.9281993844805686,\n",
       " 'test_auc': 0.8397054698457221,\n",
       " 'is_tuned': True,\n",
       " 'fpr': array([0.        , 0.15869565, 1.        ]),\n",
       " 'tpr': array([0.        , 0.66129032, 1.        ])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1935\n",
      "False Positives: 365\n",
      "False Negatives: 42\n",
      "True Positives: 82\n"
     ]
    }
   ],
   "source": [
    "lr_tuned_lin_recall = get_model_scores_cs('lr_tuned_lin', 'lr', mod_params=lr_params_V2, grid_search=True, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d533cfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayy Jangam\\.conda\\envs\\dsi\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 20, 'lr__penalty': 'l1'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'lr_tuned_lin_roc_auc',\n",
       " 'model': 'lr',\n",
       " 'train_score': 0.9282118338982266,\n",
       " 'test_score': 0.8399894810659188,\n",
       " 'recall': 0.6693548387096774,\n",
       " 'specificity': 0.841304347826087,\n",
       " 'precision': 0.18526785714285715,\n",
       " 'train_auc': 0.9282118338982266,\n",
       " 'test_auc': 0.8399894810659188,\n",
       " 'is_tuned': True,\n",
       " 'fpr': array([0.        , 0.15869565, 1.        ]),\n",
       " 'tpr': array([0.        , 0.66935484, 1.        ])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1935\n",
      "False Positives: 365\n",
      "False Negatives: 41\n",
      "True Positives: 83\n"
     ]
    }
   ],
   "source": [
    "lr_tuned_lin_roc_auc = get_model_scores_cs('lr_tuned_lin_roc_auc', 'lr', mod_params=lr_params_V2, grid_search=True, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8a0e1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>recall</th>\n",
       "      <th>test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_tuned_lin</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.839705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_tuned_lin_roc_auc</td>\n",
       "      <td>0.669355</td>\n",
       "      <td>0.839989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name    recall  test_auc\n",
       "0          lr_tuned_lin  0.661290  0.839705\n",
       "1  lr_tuned_lin_roc_auc  0.669355  0.839989"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_logreg_scores = pd.DataFrame(model_eval)\n",
    "\n",
    "lin_logreg_scores[['model_name', 'recall', 'test_auc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296e6cad",
   "metadata": {},
   "source": [
    "Now that we have tuned our best logistic regression model, let's try putting this logistic regression as the base estimator in our gradient boost and ada boost models, with the best params that we found out for our logistic regression we found previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0dcad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a48b030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'lr': LogisticRegression(max_iter=5_000, random_state=42),\n",
    "          'gb': GradientBoostingClassifier(random_state=42, init=LogisticRegression(max_iter=5000, C=20, penalty='l2')),\n",
    "          'ada': AdaBoostClassifier(random_state=42, base_estimator=LogisticRegression(max_iter=5000, C=20, penalty='l2')),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b813fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating tuning parameters to reduce model run time\n",
    "# based on previously identified best params\n",
    "\n",
    "ada_params_V2 = {'ada__n_estimators': [1500],\n",
    "              'ada__learning_rate': [1.0]\n",
    "             }\n",
    "\n",
    "gb_params = {'gb__n_estimators': [500, 1000, 1500],\n",
    "             'gb__learning_rate': [0.2, 0.3, 0.4, 0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a36e00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "gb_logreg_recall = get_model_scores_cs('gb_logreg_recall',\n",
    "                                       'gb', mod_params=gb_params, \n",
    "                                       grid_search=True, \n",
    "                                       scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e004dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gb__learning_rate': 0.2, 'gb__n_estimators': 500}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'gb_logreg_auc',\n",
       " 'model': 'gb',\n",
       " 'train_score': 0.9996923666743202,\n",
       " 'test_score': 0.8522335203366058,\n",
       " 'recall': 0.24193548387096775,\n",
       " 'specificity': 0.9778260869565217,\n",
       " 'precision': 0.37037037037037035,\n",
       " 'train_auc': 0.9996923666743202,\n",
       " 'test_auc': 0.8522335203366058,\n",
       " 'is_tuned': True,\n",
       " 'fpr': array([0.        , 0.02217391, 1.        ]),\n",
       " 'tpr': array([0.        , 0.24193548, 1.        ])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2249\n",
      "False Positives: 51\n",
      "False Negatives: 94\n",
      "True Positives: 30\n"
     ]
    }
   ],
   "source": [
    "gb_logreg_auc = get_model_scores_cs('gb_logreg_auc', \n",
    "                                    'gb', mod_params=gb_params, \n",
    "                                    grid_search=True, \n",
    "                                    scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a813d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_logreg_recall = get_model_scores_cs('ada_logreg_recall', \n",
    "                                        'ada', mod_params=ada_params, \n",
    "                                        grid_search=True, \n",
    "                                        scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99db74f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ada__learning_rate': 1.0, 'ada__n_estimators': 1500}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'ada_logreg_auc',\n",
       " 'model': 'ada',\n",
       " 'train_score': 0.9263486342504335,\n",
       " 'test_score': 0.8382924263674614,\n",
       " 'recall': 0.6854838709677419,\n",
       " 'specificity': 0.8452173913043478,\n",
       " 'precision': 0.1927437641723356,\n",
       " 'train_auc': 0.9263486342504335,\n",
       " 'test_auc': 0.8382924263674614,\n",
       " 'is_tuned': True,\n",
       " 'fpr': array([0.        , 0.15478261, 1.        ]),\n",
       " 'tpr': array([0.        , 0.68548387, 1.        ])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1944\n",
      "False Positives: 356\n",
      "False Negatives: 39\n",
      "True Positives: 85\n"
     ]
    }
   ],
   "source": [
    "ada_logreg_auc = get_model_scores_cs('ada_logreg_auc', \n",
    "                                     'ada', mod_params=ada_params_V2, \n",
    "                                     grid_search=True, \n",
    "                                     scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b396cfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ada__learning_rate': 1.0, 'ada__n_estimators': 1500}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'ada_logreg_auc',\n",
       " 'model': 'ada',\n",
       " 'train_score': 0.9263512884410001,\n",
       " 'test_score': 0.8374018232819074,\n",
       " 'recall': 0.6854838709677419,\n",
       " 'specificity': 0.8456521739130435,\n",
       " 'precision': 0.19318181818181818,\n",
       " 'train_auc': 0.9263512884410001,\n",
       " 'test_auc': 0.8374018232819074,\n",
       " 'is_tuned': True,\n",
       " 'fpr': array([0.        , 0.15434783, 1.        ]),\n",
       " 'tpr': array([0.        , 0.68548387, 1.        ])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1945\n",
      "False Positives: 355\n",
      "False Negatives: 39\n",
      "True Positives: 85\n"
     ]
    }
   ],
   "source": [
    "ada_logreg_auc_V2 = get_model_scores_cs('ada_logreg_auc', \n",
    "                                     'ada', mod_params=ada_params_V2, \n",
    "                                     grid_search=True, \n",
    "                                     scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cbe45db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>is_tuned</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_tuned_lin</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.900726</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.841304</td>\n",
       "      <td>0.183445</td>\n",
       "      <td>0.928199</td>\n",
       "      <td>0.839705</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0, 0.15869565217391304, 1.0]</td>\n",
       "      <td>[0.0, 0.6612903225806451, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_tuned_lin_roc_auc</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.928212</td>\n",
       "      <td>0.839989</td>\n",
       "      <td>0.669355</td>\n",
       "      <td>0.841304</td>\n",
       "      <td>0.185268</td>\n",
       "      <td>0.928212</td>\n",
       "      <td>0.839989</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0, 0.15869565217391304, 1.0]</td>\n",
       "      <td>[0.0, 0.6693548387096774, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ada_logreg_auc</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.926349</td>\n",
       "      <td>0.838292</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.845217</td>\n",
       "      <td>0.192744</td>\n",
       "      <td>0.926349</td>\n",
       "      <td>0.838292</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0, 0.15478260869565216, 1.0]</td>\n",
       "      <td>[0.0, 0.6854838709677419, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gb_logreg_auc</td>\n",
       "      <td>gb</td>\n",
       "      <td>0.999692</td>\n",
       "      <td>0.852234</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.977826</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.999692</td>\n",
       "      <td>0.852234</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0, 0.02217391304347826, 1.0]</td>\n",
       "      <td>[0.0, 0.24193548387096775, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ada_logreg_auc</td>\n",
       "      <td>ada</td>\n",
       "      <td>0.926351</td>\n",
       "      <td>0.837402</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.845652</td>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.926351</td>\n",
       "      <td>0.837402</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0, 0.15434782608695652, 1.0]</td>\n",
       "      <td>[0.0, 0.6854838709677419, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name model  train_score  test_score    recall  specificity  \\\n",
       "0          lr_tuned_lin    lr     0.900726    0.661290  0.661290     0.841304   \n",
       "1  lr_tuned_lin_roc_auc    lr     0.928212    0.839989  0.669355     0.841304   \n",
       "2        ada_logreg_auc   ada     0.926349    0.838292  0.685484     0.845217   \n",
       "3         gb_logreg_auc    gb     0.999692    0.852234  0.241935     0.977826   \n",
       "4        ada_logreg_auc   ada     0.926351    0.837402  0.685484     0.845652   \n",
       "\n",
       "   precision  train_auc  test_auc  is_tuned                              fpr  \\\n",
       "0   0.183445   0.928199  0.839705      True  [0.0, 0.15869565217391304, 1.0]   \n",
       "1   0.185268   0.928212  0.839989      True  [0.0, 0.15869565217391304, 1.0]   \n",
       "2   0.192744   0.926349  0.838292      True  [0.0, 0.15478260869565216, 1.0]   \n",
       "3   0.370370   0.999692  0.852234      True  [0.0, 0.02217391304347826, 1.0]   \n",
       "4   0.193182   0.926351  0.837402      True  [0.0, 0.15434782608695652, 1.0]   \n",
       "\n",
       "                               tpr  \n",
       "0   [0.0, 0.6612903225806451, 1.0]  \n",
       "1   [0.0, 0.6693548387096774, 1.0]  \n",
       "2   [0.0, 0.6854838709677419, 1.0]  \n",
       "3  [0.0, 0.24193548387096775, 1.0]  \n",
       "4   [0.0, 0.6854838709677419, 1.0]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_eval = pd.DataFrame(model_eval)\n",
    "final_model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6d381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eeb6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c4c7348",
   "metadata": {},
   "source": [
    "### Boosting our best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53207a34",
   "metadata": {},
   "source": [
    "We have substantially increased our model's performance by making use of linear regression. Let's also pass this model as a base estimator into our adaboost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3645403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55cfa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2dd5c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "models = {'lr': LogisticRegression(max_iter=5_000, random_state=42, solver='saga'),\n",
    "          'rf': RandomForestClassifier(random_state=42),\n",
    "          'gb': GradientBoostingClassifier(random_state=42, init=LogisticRegression(C=20, penalty='l2')),\n",
    "          'et': ExtraTreesClassifier(random_state=42),\n",
    "          'ada': AdaBoostClassifier(random_state=42, base_estimator=LogisticRegression(C=20, penalty='l2')),\n",
    "          'svm': SVC(random_state=42, probability=True),\n",
    "          'xgb': XGBClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29d17a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ada__learning_rate': 0.95, 'ada__n_estimators': 500}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'ada_logreg_trial_recall',\n",
       " 'model': 'ada',\n",
       " 'train_score': 0.860522496371553,\n",
       " 'test_score': 0.6048387096774194,\n",
       " 'recall': 0.6048387096774194,\n",
       " 'specificity': 0.7934782608695652,\n",
       " 'precision': 0.13636363636363635,\n",
       " 'train_auc': 0.8863228190874219,\n",
       " 'test_auc': 0.7761553295932679,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1825\n",
      "False Positives: 475\n",
      "False Negatives: 49\n",
      "True Positives: 75\n"
     ]
    }
   ],
   "source": [
    "ada_logreg_trial_recall = get_model_scores_cs('ada_logreg_trial_recall', \n",
    "                                              'ada', mod_params=ada_params, \n",
    "                                              grid_search=True, \n",
    "                                              scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d28c59f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ada__learning_rate': 1.0, 'ada__n_estimators': 1500}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'ada_logreg_trial_auc',\n",
       " 'model': 'ada',\n",
       " 'train_score': 0.8886794032705525,\n",
       " 'test_score': 0.7807836605890603,\n",
       " 'recall': 0.5967741935483871,\n",
       " 'specificity': 0.7952173913043479,\n",
       " 'precision': 0.13577981651376148,\n",
       " 'train_auc': 0.8886794032705525,\n",
       " 'test_auc': 0.7807836605890603,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1829\n",
      "False Positives: 471\n",
      "False Negatives: 50\n",
      "True Positives: 74\n"
     ]
    }
   ],
   "source": [
    "ada_logreg_trial_auc = get_model_scores_cs('ada_logreg_trial_auc', \n",
    "                                              'ada', mod_params=ada_params, \n",
    "                                              grid_search=True, \n",
    "                                              scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f4043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94c2a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_logreg_recall = get_model_scores_cs('gb_logreg_recall', 'gb', mod_params=gb_params, grid_search=True, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f26b84b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "BEST PARAMS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gb__learning_rate': 0.2, 'gb__n_estimators': 1000}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'gb_tuned_roc_auc',\n",
       " 'model': 'gb',\n",
       " 'train_score': 0.9995808801380179,\n",
       " 'test_score': 0.8463025946704067,\n",
       " 'recall': 0.1774193548387097,\n",
       " 'specificity': 0.9782608695652174,\n",
       " 'precision': 0.3055555555555556,\n",
       " 'train_auc': 0.9995808801380179,\n",
       " 'test_auc': 0.8463025946704067,\n",
       " 'is_tuned': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2250\n",
      "False Positives: 50\n",
      "False Negatives: 102\n",
      "True Positives: 22\n"
     ]
    }
   ],
   "source": [
    "gb_logreg_roc_auc = get_model_scores_cs('gb_logreg_roc_auc', 'gb', mod_params=gb_params, grid_search=True, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec3885f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d0932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall(model,model_label):\n",
    "    \"\"\"Doc String\"\"\"\n",
    "    probs = model.predict_proba(x_test_sc)\n",
    "    # Keep probabilities for the positive outcome only\n",
    "    probs = probs[:, 1]\n",
    "    # Predict class values\n",
    "    yhat = model.predict(x_test_sc)\n",
    "    # Calculate precision-recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_test, yhat)\n",
    "    # Calculate precision-recall AUC\n",
    "    auc_score = auc(recall, precision)\n",
    "    # Calculate average precision score\n",
    "    ap = average_precision_score(y_test, probs)\n",
    "    print(f'log_reg: f1=%.3f pr-auc=%.3f avg. prec=%.3f' % (f1, auc_score, ap))\n",
    "    # Plot the ROC curve for the model\n",
    "    plt.plot(recall, precision, marker='.', label=model_label)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78607a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8795496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e5fe55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
