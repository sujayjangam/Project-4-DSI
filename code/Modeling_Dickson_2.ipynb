{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0669e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import datetime as dt\n",
    "from dateutil.parser import *\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from numpy import argmax\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score,classification_report, roc_auc_score,accuracy_score, \\\n",
    "precision_score, f1_score, recall_score, roc_curve\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import re\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rc('xtick', labelsize=12) \n",
    "plt.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac99645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression = pd.read_csv('../data/merged_train_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c27b2160",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_regression = pd.read_csv('../data/merged_test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3c123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_multi = pd.read_csv('../data/merged_train_multi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2d8d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test_multi = pd.read_csv('../data/merged_test_multi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d022cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.948107\n",
       "1    0.051893\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df_regression.drop(['wnvpresent'],axis=1)\n",
    "y = df_regression['wnvpresent']\n",
    "\n",
    "#x = merged_train_multi.drop(['wnvpresent'],axis=1)\n",
    "#y = merged_train_multi['wnvpresent']\n",
    "\n",
    "display(y.value_counts(normalize=True))\n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(x,y,random_state=42)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train_sc = ss.fit_transform(x_train)\n",
    "x_test_sc = ss.transform(x_test)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "x_train_sc, y_train = sm.fit_resample(x_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d43ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "models = {'lr': LogisticRegression(max_iter=5_000, random_state=42, solver='saga'),\n",
    "          'rf': RandomForestClassifier(random_state=42),\n",
    "          'gb': GradientBoostingClassifier(random_state=42),\n",
    "          'et': ExtraTreesClassifier(random_state=42),\n",
    "          'ada': AdaBoostClassifier(random_state=42),\n",
    "          'svm': SVC(random_state=42, probability=True),\n",
    "          'xg': XGBClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ba6eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run model -- input model\n",
    "def get_model_scores(model_name,\n",
    "                     mod, \n",
    "                     mod_params={}, \n",
    "                     grid_search=False):\n",
    "    \n",
    "    \"\"\"Function accepts following inputs:\n",
    "    Name of model (str), model to be used (str), \n",
    "    model params(dict, optional), grid_seach(boolean, optional)\n",
    "    If grid_search is True, then please also input the relevant \n",
    "    params for GridSearching\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty dict for appending results\n",
    "    results = {}\n",
    "    \n",
    "    # instantiate pipe\n",
    "    pipe = Pipeline([\n",
    "            (mod, models[mod])\n",
    "            ])\n",
    "    \n",
    "    # check if GridSearch true or false\n",
    "    if grid_search:\n",
    "        \n",
    "        # combine vectorizer and mod params together\n",
    "        gs_params = {}\n",
    "        gs_params.update(mod_params)\n",
    "        \n",
    "        # instantiate GridSearchCV\n",
    "        gs = GridSearchCV(pipe, \n",
    "                          param_grid=gs_params,\n",
    "                          cv=5, \n",
    "                          verbose=2, \n",
    "                          n_jobs=-1)\n",
    "        \n",
    "        # fit model\n",
    "        gs.fit(x_train_sc, y_train)\n",
    "        pipe = gs\n",
    "        \n",
    "    else:\n",
    "        # else fit model\n",
    "        pipe.fit(x_train_sc, y_train)\n",
    "    \n",
    "    # create predictions and confusion matrix\n",
    "    predictions = pipe.predict(x_test_sc)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    y_test_pred_prob = pipe.predict_proba(x_test_sc)[:,1]\n",
    "    y_train_pred_prob = pipe.predict_proba(x_train_sc)[:,1]\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred_prob)\n",
    "    test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    \n",
    "    # Retrieve metrics and add to results\n",
    "    results['model_name'] = model_name\n",
    "    results['model'] = mod\n",
    "    results['train_score'] = pipe.score(x_train_sc, y_train)\n",
    "    results['test_score'] = pipe.score(x_test_sc, y_test)\n",
    "    \n",
    "    results['recall'] = recall_score(y_test, \n",
    "                                     predictions)\n",
    "    \n",
    "    results['specificity'] = tn/(tn + fp)\n",
    "    \n",
    "    results['precision'] = precision_score(y_test, \n",
    "                                           predictions)\n",
    "    \n",
    "    results['train_auc'] = roc_auc_score(y_train, y_train_pred_prob)\n",
    "    results['test_auc'] = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    \n",
    "    results['is_tuned'] = grid_search\n",
    "    \n",
    "    if grid_search:\n",
    "        print('BEST PARAMS-->')\n",
    "        display(pipe.best_params_)\n",
    "    \n",
    "    # add results to list for model evaluation later\n",
    "    model_eval.append(results)\n",
    "    \n",
    "    print('METRICS-->')\n",
    "    display(results)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    \n",
    "    print(f\"True Negatives: {tn}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"True Positives: {tp}\")\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce484811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to store results\n",
    "model_eval =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e455ed0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'lr_base',\n",
       " 'model': 'lr',\n",
       " 'train_score': 0.8057329462989841,\n",
       " 'test_score': 0.7541254125412541,\n",
       " 'recall': 0.5887096774193549,\n",
       " 'specificity': 0.7630434782608696,\n",
       " 'precision': 0.11812297734627832,\n",
       " 'train_auc': 0.8751527212826059,\n",
       " 'test_auc': 0.7461448106591865,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1755\n",
      "False Positives: 545\n",
      "False Negatives: 51\n",
      "True Positives: 73\n"
     ]
    }
   ],
   "source": [
    "lr_base = get_model_scores('lr_base', 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec9f86be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'svm_base',\n",
       " 'model': 'svm',\n",
       " 'train_score': 0.9130624092888244,\n",
       " 'test_score': 0.8407590759075908,\n",
       " 'recall': 0.4274193548387097,\n",
       " 'specificity': 0.8630434782608696,\n",
       " 'precision': 0.14402173913043478,\n",
       " 'train_auc': 0.9712810577160058,\n",
       " 'test_auc': 0.7514708976157083,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1985\n",
      "False Positives: 315\n",
      "False Negatives: 71\n",
      "True Positives: 53\n"
     ]
    }
   ],
   "source": [
    "svm_base = get_model_scores('svm_base', 'svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bdd4fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:03:14] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user_1/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'xg_base',\n",
       " 'model': 'xg',\n",
       " 'train_score': 0.9776487663280116,\n",
       " 'test_score': 0.9426567656765676,\n",
       " 'recall': 0.08064516129032258,\n",
       " 'specificity': 0.9891304347826086,\n",
       " 'precision': 0.2857142857142857,\n",
       " 'train_auc': 0.9971802490304831,\n",
       " 'test_auc': 0.8572072230014025,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2275\n",
      "False Positives: 25\n",
      "False Negatives: 114\n",
      "True Positives: 10\n"
     ]
    }
   ],
   "source": [
    "xg_base = get_model_scores('xg_base', 'xg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "204bb531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'et_base',\n",
       " 'model': 'et',\n",
       " 'train_score': 0.9918722786647315,\n",
       " 'test_score': 0.941006600660066,\n",
       " 'recall': 0.07258064516129033,\n",
       " 'specificity': 0.9878260869565217,\n",
       " 'precision': 0.24324324324324326,\n",
       " 'train_auc': 0.9998393056131918,\n",
       " 'test_auc': 0.6866374474053296,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2272\n",
      "False Positives: 28\n",
      "False Negatives: 115\n",
      "True Positives: 9\n"
     ]
    }
   ],
   "source": [
    "et_base = get_model_scores('et_base', 'et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7424924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_name': 'lr_base',\n",
       "  'model': 'lr',\n",
       "  'train_score': 0.8057329462989841,\n",
       "  'test_score': 0.7541254125412541,\n",
       "  'recall': 0.5887096774193549,\n",
       "  'specificity': 0.7630434782608696,\n",
       "  'precision': 0.11812297734627832,\n",
       "  'train_auc': 0.8751527212826059,\n",
       "  'test_auc': 0.7461448106591865,\n",
       "  'is_tuned': False},\n",
       " {'model_name': 'svm_base',\n",
       "  'model': 'svm',\n",
       "  'train_score': 0.9130624092888244,\n",
       "  'test_score': 0.8407590759075908,\n",
       "  'recall': 0.4274193548387097,\n",
       "  'specificity': 0.8630434782608696,\n",
       "  'precision': 0.14402173913043478,\n",
       "  'train_auc': 0.9712810577160058,\n",
       "  'test_auc': 0.7514708976157083,\n",
       "  'is_tuned': False},\n",
       " {'model_name': 'xg_base',\n",
       "  'model': 'xg',\n",
       "  'train_score': 0.9776487663280116,\n",
       "  'test_score': 0.9426567656765676,\n",
       "  'recall': 0.08064516129032258,\n",
       "  'specificity': 0.9891304347826086,\n",
       "  'precision': 0.2857142857142857,\n",
       "  'train_auc': 0.9971802490304831,\n",
       "  'test_auc': 0.8572072230014025,\n",
       "  'is_tuned': False},\n",
       " {'model_name': 'et_base',\n",
       "  'model': 'et',\n",
       "  'train_score': 0.9918722786647315,\n",
       "  'test_score': 0.941006600660066,\n",
       "  'recall': 0.07258064516129033,\n",
       "  'specificity': 0.9878260869565217,\n",
       "  'precision': 0.24324324324324326,\n",
       "  'train_auc': 0.9998393056131918,\n",
       "  'test_auc': 0.6866374474053296,\n",
       "  'is_tuned': False}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28d345fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.948107\n",
       "1    0.051893\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#x = df_regression.drop(['wnvpresent'],axis=1)\n",
    "#y = df_regression['wnvpresent']\n",
    "\n",
    "x = merged_train_multi.drop(['wnvpresent'],axis=1)\n",
    "y = merged_train_multi['wnvpresent']\n",
    "\n",
    "display(y.value_counts(normalize=True))\n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(x,y,random_state=42)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train_sc = ss.fit_transform(x_train)\n",
    "x_test_sc = ss.transform(x_test)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "x_train_sc, y_train = sm.fit_resample(x_train_sc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99c4cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    # Trying different types of regularization\n",
    "    'lr__penalty':['l2','l1', 'elasticnet'],\n",
    "\n",
    "     # Trying different alphas of: 1, 0.1, 0.05  (C = 1/alpha)\n",
    "    'lr__C':[1, 10, 20],\n",
    "\n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "    'svc__C':[10, 30],\n",
    "    'svc__gamma':[0.01, 0.1], \n",
    "    'svc__kernel':['rbf', 'sigmoid'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9ed1113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run model -- input model\n",
    "def get_model_scores(model_name,\n",
    "                     mod, \n",
    "                     mod_params={}, \n",
    "                     grid_search=False):\n",
    "    \n",
    "    \"\"\"Function accepts following inputs:\n",
    "    Name of model (str), model to be used (str), \n",
    "    model params(dict, optional), grid_seach(boolean, optional)\n",
    "    If grid_search is True, then please also input the relevant \n",
    "    params for GridSearching\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty dict for appending results\n",
    "    results = {}\n",
    "    \n",
    "    # instantiate pipe\n",
    "    pipe = Pipeline([\n",
    "            (mod, models[mod])\n",
    "            ])\n",
    "    \n",
    "    # check if GridSearch true or false\n",
    "    if grid_search:\n",
    "        \n",
    "        # combine vectorizer and mod params together\n",
    "        gs_params = {}\n",
    "        gs_params.update(mod_params)\n",
    "        \n",
    "        # instantiate GridSearchCV\n",
    "        gs = GridSearchCV(pipe, \n",
    "                          param_grid=gs_params,\n",
    "                          cv=5, \n",
    "                          verbose=2, \n",
    "                          n_jobs=-1)\n",
    "        \n",
    "        # fit model\n",
    "        gs.fit(x_train_sc, y_train)\n",
    "        pipe = gs\n",
    "        \n",
    "    else:\n",
    "        # else fit model\n",
    "        pipe.fit(x_train_sc, y_train)\n",
    "    \n",
    "    # create predictions and confusion matrix\n",
    "    predictions = pipe.predict(x_test_sc)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    y_test_pred_prob = pipe.predict_proba(x_test_sc)[:,1]\n",
    "    y_train_pred_prob = pipe.predict_proba(x_train_sc)[:,1]\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred_prob)\n",
    "    test_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    \n",
    "    # Retrieve metrics and add to results\n",
    "    results['model_name'] = model_name\n",
    "    results['model'] = mod\n",
    "    results['train_score'] = pipe.score(x_train_sc, y_train)\n",
    "    results['test_score'] = pipe.score(x_test_sc, y_test)\n",
    "    \n",
    "    results['recall'] = recall_score(y_test, \n",
    "                                     predictions)\n",
    "    \n",
    "    results['specificity'] = tn/(tn + fp)\n",
    "    \n",
    "    results['precision'] = precision_score(y_test, \n",
    "                                           predictions)\n",
    "    \n",
    "    results['train_auc'] = roc_auc_score(y_train, y_train_pred_prob)\n",
    "    results['test_auc'] = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    \n",
    "    results['is_tuned'] = grid_search\n",
    "    \n",
    "    if grid_search:\n",
    "        print('BEST PARAMS-->')\n",
    "        display(pipe.best_params_)\n",
    "    \n",
    "    # add results to list for model evaluation later\n",
    "    model_eval_2.append(results)\n",
    "    \n",
    "    print('METRICS-->')\n",
    "    display(results)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, \n",
    "                                      predictions).ravel()\n",
    "    \n",
    "    print(f\"True Negatives: {tn}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"True Positives: {tp}\")\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bd72a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9be933c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'lr_base',\n",
       " 'model': 'lr',\n",
       " 'train_score': 0.8259796806966618,\n",
       " 'test_score': 0.775990099009901,\n",
       " 'recall': 0.6048387096774194,\n",
       " 'specificity': 0.7852173913043479,\n",
       " 'precision': 0.13181019332161686,\n",
       " 'train_auc': 0.8874044228083443,\n",
       " 'test_auc': 0.7729926367461429,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1806\n",
      "False Positives: 494\n",
      "False Negatives: 49\n",
      "True Positives: 75\n"
     ]
    }
   ],
   "source": [
    "lr_base = get_model_scores('lr_base', 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a48b3dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'svm_base',\n",
       " 'model': 'svm',\n",
       " 'train_score': 0.9298984034833091,\n",
       " 'test_score': 0.8535478547854786,\n",
       " 'recall': 0.45161290322580644,\n",
       " 'specificity': 0.8752173913043478,\n",
       " 'precision': 0.16326530612244897,\n",
       " 'train_auc': 0.9783968162352202,\n",
       " 'test_auc': 0.777312412342216,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2013\n",
      "False Positives: 287\n",
      "False Negatives: 68\n",
      "True Positives: 56\n"
     ]
    }
   ],
   "source": [
    "svm_base = get_model_scores('svm_base', 'svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "187a0c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user_1/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'xg_base',\n",
       " 'model': 'xg',\n",
       " 'train_score': 0.978011611030479,\n",
       " 'test_score': 0.9422442244224423,\n",
       " 'recall': 0.0967741935483871,\n",
       " 'specificity': 0.9878260869565217,\n",
       " 'precision': 0.3,\n",
       " 'train_auc': 0.9974362836276467,\n",
       " 'test_auc': 0.8528962131837308,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2272\n",
      "False Positives: 28\n",
      "False Negatives: 112\n",
      "True Positives: 12\n"
     ]
    }
   ],
   "source": [
    "xg_base = get_model_scores('xg_base', 'xg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "674ac2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS-->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'et_base',\n",
       " 'model': 'et',\n",
       " 'train_score': 0.9918722786647315,\n",
       " 'test_score': 0.9426567656765676,\n",
       " 'recall': 0.06451612903225806,\n",
       " 'specificity': 0.99,\n",
       " 'precision': 0.25806451612903225,\n",
       " 'train_auc': 0.9998393056131918,\n",
       " 'test_auc': 0.70117110799439,\n",
       " 'is_tuned': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 2277\n",
      "False Positives: 23\n",
      "False Negatives: 116\n",
      "True Positives: 8\n"
     ]
    }
   ],
   "source": [
    "et_base = get_model_scores('et_base', 'et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "756306fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_name': 'lr_base',\n",
       "  'model': 'lr',\n",
       "  'train_score': 0.8259796806966618,\n",
       "  'test_score': 0.775990099009901,\n",
       "  'recall': 0.6048387096774194,\n",
       "  'specificity': 0.7852173913043479,\n",
       "  'precision': 0.13181019332161686,\n",
       "  'train_auc': 0.8874044228083443,\n",
       "  'test_auc': 0.7729926367461429,\n",
       "  'is_tuned': False},\n",
       " {'model_name': 'svm_base',\n",
       "  'model': 'svm',\n",
       "  'train_score': 0.9298984034833091,\n",
       "  'test_score': 0.8535478547854786,\n",
       "  'recall': 0.45161290322580644,\n",
       "  'specificity': 0.8752173913043478,\n",
       "  'precision': 0.16326530612244897,\n",
       "  'train_auc': 0.9783968162352202,\n",
       "  'test_auc': 0.777312412342216,\n",
       "  'is_tuned': False},\n",
       " {'model_name': 'xg_base',\n",
       "  'model': 'xg',\n",
       "  'train_score': 0.978011611030479,\n",
       "  'test_score': 0.9422442244224423,\n",
       "  'recall': 0.0967741935483871,\n",
       "  'specificity': 0.9878260869565217,\n",
       "  'precision': 0.3,\n",
       "  'train_auc': 0.9974362836276467,\n",
       "  'test_auc': 0.8528962131837308,\n",
       "  'is_tuned': False},\n",
       " {'model_name': 'et_base',\n",
       "  'model': 'et',\n",
       "  'train_score': 0.9918722786647315,\n",
       "  'test_score': 0.9426567656765676,\n",
       "  'recall': 0.06451612903225806,\n",
       "  'specificity': 0.99,\n",
       "  'precision': 0.25806451612903225,\n",
       "  'train_auc': 0.9998393056131918,\n",
       "  'test_auc': 0.70117110799439,\n",
       "  'is_tuned': False}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e37b212d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>is_tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_base</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.805733</td>\n",
       "      <td>0.754125</td>\n",
       "      <td>0.588710</td>\n",
       "      <td>0.763043</td>\n",
       "      <td>0.118123</td>\n",
       "      <td>0.875153</td>\n",
       "      <td>0.746145</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm_base</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.913062</td>\n",
       "      <td>0.840759</td>\n",
       "      <td>0.427419</td>\n",
       "      <td>0.863043</td>\n",
       "      <td>0.144022</td>\n",
       "      <td>0.971281</td>\n",
       "      <td>0.751471</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xg_base</td>\n",
       "      <td>xg</td>\n",
       "      <td>0.977649</td>\n",
       "      <td>0.942657</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.997180</td>\n",
       "      <td>0.857207</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>et_base</td>\n",
       "      <td>et</td>\n",
       "      <td>0.991872</td>\n",
       "      <td>0.941007</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.987826</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>0.686637</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_base</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.825980</td>\n",
       "      <td>0.775990</td>\n",
       "      <td>0.604839</td>\n",
       "      <td>0.785217</td>\n",
       "      <td>0.131810</td>\n",
       "      <td>0.887404</td>\n",
       "      <td>0.772993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm_base</td>\n",
       "      <td>svm</td>\n",
       "      <td>0.929898</td>\n",
       "      <td>0.853548</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.875217</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.978397</td>\n",
       "      <td>0.777312</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xg_base</td>\n",
       "      <td>xg</td>\n",
       "      <td>0.978012</td>\n",
       "      <td>0.942244</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.987826</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>0.852896</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>et_base</td>\n",
       "      <td>et</td>\n",
       "      <td>0.991872</td>\n",
       "      <td>0.942657</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>0.701171</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name model  train_score  test_score    recall  specificity  precision  \\\n",
       "0    lr_base    lr     0.805733    0.754125  0.588710     0.763043   0.118123   \n",
       "1   svm_base   svm     0.913062    0.840759  0.427419     0.863043   0.144022   \n",
       "2    xg_base    xg     0.977649    0.942657  0.080645     0.989130   0.285714   \n",
       "3    et_base    et     0.991872    0.941007  0.072581     0.987826   0.243243   \n",
       "0    lr_base    lr     0.825980    0.775990  0.604839     0.785217   0.131810   \n",
       "1   svm_base   svm     0.929898    0.853548  0.451613     0.875217   0.163265   \n",
       "2    xg_base    xg     0.978012    0.942244  0.096774     0.987826   0.300000   \n",
       "3    et_base    et     0.991872    0.942657  0.064516     0.990000   0.258065   \n",
       "\n",
       "   train_auc  test_auc  is_tuned  \n",
       "0   0.875153  0.746145     False  \n",
       "1   0.971281  0.751471     False  \n",
       "2   0.997180  0.857207     False  \n",
       "3   0.999839  0.686637     False  \n",
       "0   0.887404  0.772993     False  \n",
       "1   0.978397  0.777312     False  \n",
       "2   0.997436  0.852896     False  \n",
       "3   0.999839  0.701171     False  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.concat([pd.DataFrame(model_eval),pd.DataFrame(model_eval_2)])\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10224757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.129008\n",
       "1    0.219810\n",
       "2    0.139973\n",
       "3    0.313202\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overtrain_s = eval_df['train_auc'] - eval_df['test_auc']\n",
    "\n",
    "# remove multi with vif\n",
    "overtrain_s[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f62ef9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20049823874016492"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overtrain_s[:4].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ea78cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.114412\n",
       "1    0.201084\n",
       "2    0.144540\n",
       "3    0.298668\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore multi, no vif\n",
    "overtrain_s[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b3dfafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18967611450448082"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overtrain_s[4:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680c3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
